---
title: About
permalink: /about/
layout: page
excerpt: Goal A robust way to train reinforcemnt learning agents without using reinforcemnt learning.
comments: false
---

Reinforcement Learning provides a framework for solving complex games such as Go, Dota and StarCraft. It however suffers from serious problems such as sample inefficiency and instability when training. You need thousands of computers to train a starcraft bot that is at the level of professional human players. Even for simple problems RL models are hard to tune and its problems, difficult to diagnose. There is a need to find a new deep learning paradigm to solve these problems.
The goal of this newsletter is to investigate ways in which reinforcement learning can be replaced by a more robust deep learning paradigm. Victory conditions are that the resulting framework will enable training of agents that solve simple, complex, single and multi agent problems in a robust, sample efficient and more diagnostic manner. The constraints I put on this research is single GPU use for training/inference and use of deep learning.
Every week I post my research findings about experimental methods to train agents without using reinforcement learning. My hope is that over the course of this research my subscribers will get to see weekly progress and suggest solutions for training robust, efficient and versatile AI agents. I aim to devise one algorithm to play games such as cartpole & Lunar lander, then on to more complex games in the atari environment and then on to even  more complex games such as Dota, Fifa and starcraft. Subscribers will get first hand knowledge on a new frontier, cool ideas to apply to their own research, in depth analysis of experiments and code solutions for experiments adapt to their own problems. 

[Subscribe](http://github.com/piharpi/jekyll-klise/issues/new) to get bimonthly reports on this ambitious research project.



##### may u needs âœ¨

- {{ site.author.email }}
- github.com/{{ site.author.username }}
